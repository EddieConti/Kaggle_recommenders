{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<small><i>Updated February 2024 - This notebook was created by [Santi Seguí](https://ssegui.github.io/). </i></small>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\afred\\AppData\\Local\\Temp\\ipykernel_24152\\3777615979.py:1: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import display, HTML\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" style = \"border-radius:10px;border-width:3px;border-color:darkgreen;font-family:Verdana,sans-serif;\">\n",
    "        <h2>Collaborative filtering:</h2>\n",
    "         <br>\n",
    "</div>\n",
    "\n",
    "<br>\n",
    "<center>Collaborative filtering methods are based on collecting and analyzing a large amount <br>of information on users’ behaviors, activities or preferences and predicting what users will like based on their similarity to other users. \n",
    "<br><br><b>Hyphothesis: Similar users tend to like similar items.</b>\n",
    "<br><b>Problem: Requires a user community.</b>\n",
    "<br>\n",
    "</center>\n",
    "\n",
    "\n",
    "It can be understood as a generalization of Supervised Classication:\n",
    "<img src=\"images/colResSys.png\" width=50%>\n",
    "<br>\n",
    "\n",
    "<p><b>Several</b> methods but <b>one (or two main) </b> approaches\n",
    "<ol>\n",
    "\n",
    "<li>Memory-Based Methods (Neighborhood-based methods) </li>\n",
    "<li>Model-Based Methods</li>\n",
    "</ol>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" style = \"border-radius:10px;border-width:3px;border-color:darkgreen;font-family:Verdana,sans-serif;\"><a class=\"anchor\" id=\"what-is-a-recommender\"></a><h3>Neighborhood-based methods</h3><br></div>\n",
    "<br>Two main types: User-based and Item-based.\n",
    "        \n",
    "* User-based CF works like this: take a user U and a set of other users D whose ratings are similar to the ratings of the selected user U and use the ratings from those like-minded users to calculate a prediction for the selected user U.\n",
    "\n",
    "<img src=https://dataaspirant.files.wordpress.com/2015/01/userbased.png width=700>\n",
    "<center>Original source: https://dataaspirant.files.wordpress.com</center>\n",
    "\n",
    "* In Item-based CF you build an item-item matrix determining relationships between pairs of items and using this matrix and data on the current user, infer the user’s taste. Typicaly used in the domain: people who buy x also buy y\n",
    "<img src=\"images/neighbourhood.png\" width=600>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" style = \"border-radius:10px;border-width:3px;border-color:darkgreen;font-family:Verdana,sans-serif;font-size:16px;\">\n",
    "EXAMPLE: Movie Recommender System. User-Based Collaborative Filtering\n",
    "</div>\n",
    "\n",
    "\n",
    "## What do we need to build a Movie Recommendation System?\n",
    "\n",
    "### Steps in order to create a CF - Recommender\n",
    "+ Data recollection\n",
    "+ Data filtering/cleaning\n",
    "+ Item/user similarity function\n",
    "+ Learning/Prediction funciton\n",
    "\n",
    "Given an \"active user\" (Joan) and an item that has not been seen by the user, the goal is to estimate the rating for the item.\n",
    "<table style=\"width:60%\">\n",
    "  <tr>\n",
    "    <td></td>\n",
    "    <td>Superman</td> \n",
    "    <td>Star Wars 1</td>\n",
    "    <td>Matrix</td>\n",
    "    <td>Spiderman</td>\n",
    "    \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Santi</td>\n",
    "    <td>3</td> \n",
    "    <td>3.5</td>\n",
    "    <td>4.5</td>\n",
    "    <td><font color=\"red\"><b>¿?</b></font></td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>User1</td>\n",
    "    <td>3.5</td> \n",
    "    <td>4</td>\n",
    "    <td>5</td>\n",
    "    <td>5</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>User2</td>\n",
    "    <td>3</td> \n",
    "    <td><font color=\"red\"><b>¿?</b></font></td>\n",
    "    <td>4.5</td>\n",
    "    <td>3</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>User3</td>\n",
    "    <td>3.5</td> \n",
    "    <td>5</td>\n",
    "    <td>3.5</td>\n",
    "    <td>2</td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "<br><br><br><br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to measure similarity between users?\n",
    "The similarity computation between the items is one critical step in the CF algorithms. The basic idea in similarity computation between two users <i>a</i> and <i>b</i> is to first isolate the items commonly rated by both users (set <i>P</i>), and then to apply a similarity computation technique to determine the similarity.\n",
    "    <ul>\n",
    "    <li>Euclidean distance</li>\n",
    "    $$sim(a,b) = \\frac{1}{1+  \\sqrt{\\sum_{p \\in P}{(r_{a,p} - r_{b,p})^2}}}$$\n",
    "    <br>\n",
    "    <li>Pearson Correlation</li>\n",
    "    $$sim(a,b) = \\frac{\\sum_{p\\in P} (r_{a,p}-\\bar{r_a})(r_{b,p}-\\bar{r_b})}{\\sqrt{\\sum_{p \\in P}(r_{a,p}-\\bar{r_a})²}\\sqrt{\\sum_{p \\in P}(r_{b,p}-\\bar{r_b})²}}$$\n",
    "    <br>\n",
    "    <li>Cosine distance</li>\n",
    "    $$ sim(a,b) = \\frac{\\vec{a}· \\vec{b}}{|\\vec{a}| * |\\vec{b}|}$$\n",
    "    <br>\n",
    "    </ul>\n",
    "<br>\n",
    "Where: \n",
    "\n",
    "* $sim(a,b)$ is the similarity between user \"a\" and user \"b\"\n",
    "* $P$ is the set of common rated movies by user \"a\" and \"b\"\n",
    "* $r_{a,p}$ is the rating of movie \"p\" by user \"a\"\n",
    "* $\\bar{r_a}$ is the mean rating given by user \"a\"\n",
    "\n",
    "<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Some issues to take into accout</h3>\n",
    "<ul>\n",
    "<li>Pearson Correlation used to work better than euclidean distance since it is based more on the ranking than on the values.</li>\n",
    "<li>Cosine distance is usually used when our data is binary/unary, i.e. like vs. not like  or buy vs. not buy.</li>\n",
    "<li>What happens if two users have very few items in common?</li>\n",
    "</ul>\n",
    "\n",
    "\n",
    "<h3>How do we generate a prediction from the neighbour's ratings?</h3><br>\n",
    "\n",
    "$$pred(a,p) = \\frac{\\sum_{b \\in N}{sim(a,b)*(r_{b,p})}}{\\sum_{b \\in N}{sim(a,b)}}$$\n",
    "\n",
    "Example:\n",
    "<br>\n",
    "<table style=\"width:100%\">\n",
    "  <tr>\n",
    "    <td>Critic</td>\n",
    "    <td>$sim(a,b)$</td> \n",
    "    <td>Rating Movie1: $r_{b,p_1}$</td>\n",
    "    <td>$sim(a,b)*(r_{b,p_1})$</td>\n",
    "    <td>Rating Movie2: $r_{b,p_2}$</td>\n",
    "    <td>$sim(a,b)*(r_{b,p_2})$</td>\n",
    "    \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>User1</td>\n",
    "    <td>0.99</td> \n",
    "    <td>3</td>\n",
    "    <td>2.97</td>\n",
    "    <td>2.5</td>\n",
    "    <td>2.48</td>\n",
    "    \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>User2</td>\n",
    "    <td>0.38</td> \n",
    "    <td>3</td>\n",
    "    <td>1.14</td>\n",
    "    <td>3</td>\n",
    "    <td>1.14</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>User3</td>\n",
    "    <td>0.89</td>\n",
    "    <td>4.5</td>\n",
    "    <td>4.0</td>\n",
    "    <td> - </td>\n",
    "    <td> - </td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>User4</td>\n",
    "    <td>0.92</td>\n",
    "    <td>3</td>\n",
    "    <td>2.77</td>\n",
    "    <td>3</td>\n",
    "    <td>2.77</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>$\\sum_{b \\in N}{sim(a,b)*(r_{b,p})}$</td>\n",
    "    <td></td> \n",
    "    <td></td>\n",
    "    <td>10.87</td>\n",
    "    <td></td>\n",
    "    <td>6.39</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>$\\sum_{b \\in N}{sim(a,b)}$</td>\n",
    "    <td></td> \n",
    "    <td></td>\n",
    "    <td>3.18</td>\n",
    "    <td></td>\n",
    "    <td>2.29</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "  <td>$pred(a,p)$</td>\n",
    "    <td></td> \n",
    "    <td></td>\n",
    "    <td>3.41</td>\n",
    "    <td></td>\n",
    "    <td>2.79</td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation: performance criterion\n",
    "Performance evaluation of recommendation systems is an entire topic all in itself. Some of the options include:\n",
    "* $RMSE = \\sqrt{(\\frac{\\sum(\\hat{y}-y)^2}{n})}$\n",
    "* Precision / Recall / F-scores / MAP\n",
    "* ROC curves\n",
    "* Cost curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_rmse(y_pred, y_true):\n",
    "    \"\"\" Compute Root Mean Squared Error. \"\"\"\n",
    "    return np.sqrt(np.mean(np.power(y_pred - y_true, 2)))\n",
    "\n",
    "def precision(recommended_items, relevant_items):\n",
    "    is_relevant = np.in1d(recommended_items, relevant_items, assume_unique=True)\n",
    "    precision_score = np.sum(is_relevant, dtype=np.float32) / len(is_relevant)\n",
    "    \n",
    "    return precision_score\n",
    "\n",
    "def recall(recommended_items, relevant_items):  \n",
    "    is_relevant = np.in1d(recommended_items, relevant_items, assume_unique=True)\n",
    "    recall_score = np.sum(is_relevant, dtype=np.float32) / relevant_items.shape[0]\n",
    "    \n",
    "    return recall_score\n",
    "\n",
    "def AP(recommended_items, relevant_items):\n",
    "   \n",
    "    is_relevant = np.in1d(recommended_items, relevant_items, assume_unique=True)\n",
    "    # Cumulative sum: precision at 1, at 2, at 3 ...\n",
    "    p_at_k = is_relevant * np.cumsum(is_relevant, dtype=np.float32) / (1 + np.arange(is_relevant.shape[0]))\n",
    "    ap_score = np.sum(p_at_k) / np.min([relevant_items.shape[0], is_relevant.shape[0]])\n",
    "\n",
    "    return ap_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Download Movilens Database</h5>\n",
    "There is three different version of the database containing 100k, 1m and 10m ratings. We can download the smallest version for this demo.\n",
    "http://grouplens.org/datasets/movielens/\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/javascript": "IPython.notebook.set_autosave_interval(150000)"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 150 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\afred\\AppData\\Local\\Temp\\ipykernel_24152\\3299491286.py:11: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  users = pd.read_csv('./data/ml-1m/users.dat', sep='::', names=u_cols)\n",
      "C:\\Users\\afred\\AppData\\Local\\Temp\\ipykernel_24152\\3299491286.py:14: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  ratings = pd.read_csv('./data/ml-1m/ratings.dat', sep='::', names=r_cols)\n",
      "C:\\Users\\afred\\AppData\\Local\\Temp\\ipykernel_24152\\3299491286.py:19: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  movies = pd.read_csv('./data/ml-1m/movies.dat', sep='::', names=m_cols, usecols=range(3), encoding='latin-1')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La BD has 1000209 ratings\n",
      "La BD has  6040  users\n",
      "La BD has  3706  movies\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>title</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>release_date</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>One Flew Over the Cuckoo's Nest (1975)</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>Drama</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>One Flew Over the Cuckoo's Nest (1975)</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>Drama</td>\n",
       "      <td>M</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>One Flew Over the Cuckoo's Nest (1975)</td>\n",
       "      <td>1193</td>\n",
       "      <td>4</td>\n",
       "      <td>Drama</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>One Flew Over the Cuckoo's Nest (1975)</td>\n",
       "      <td>1193</td>\n",
       "      <td>4</td>\n",
       "      <td>Drama</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>One Flew Over the Cuckoo's Nest (1975)</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>Drama</td>\n",
       "      <td>M</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                                   title  movie_id  rating  \\\n",
       "0        1  One Flew Over the Cuckoo's Nest (1975)      1193       5   \n",
       "1        2  One Flew Over the Cuckoo's Nest (1975)      1193       5   \n",
       "2       12  One Flew Over the Cuckoo's Nest (1975)      1193       4   \n",
       "3       15  One Flew Over the Cuckoo's Nest (1975)      1193       4   \n",
       "4       17  One Flew Over the Cuckoo's Nest (1975)      1193       5   \n",
       "\n",
       "  release_date sex  age  \n",
       "0        Drama   F    1  \n",
       "1        Drama   M   56  \n",
       "2        Drama   M   25  \n",
       "3        Drama   M   25  \n",
       "4        Drama   M   50  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#NETFLIX REAL 50.000.000 usuaris and 100.000 items\n",
    "%autosave 150\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "# Load Data set\n",
    "u_cols = ['user_id', 'sex', 'age', 'occupation', 'zip_code']\n",
    "users = pd.read_csv('./data/ml-1m/users.dat', sep='::', names=u_cols)\n",
    "\n",
    "r_cols = ['user_id', 'movie_id', 'rating', 'unix_timestamp']\n",
    "ratings = pd.read_csv('./data/ml-1m/ratings.dat', sep='::', names=r_cols)\n",
    "\n",
    "# the movies file contains columns indicating the movie's genres\n",
    "# let's only load the first three columns of the file with usecols\n",
    "m_cols = ['movie_id', 'title', 'release_date',]\n",
    "movies = pd.read_csv('./data/ml-1m/movies.dat', sep='::', names=m_cols, usecols=range(3), encoding='latin-1')\n",
    "\n",
    "# Construcció del DataFrame\n",
    "data = pd.merge(pd.merge(ratings, users), movies)\n",
    "data = data[['user_id','title', 'movie_id','rating','release_date','sex','age']]\n",
    "\n",
    "\n",
    "n_users = data.user_id.nunique()\n",
    "n_items = data.movie_id.nunique()\n",
    "print(\"La BD has \"+ str(data.shape[0]) +\" ratings\")\n",
    "print(\"La BD has \", n_users,\" users\")\n",
    "print(\"La BD has \", n_items, \" movies\")\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Divide the data in two sets: training and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(797758, 8) (202451, 8)\n",
      "Training data_set has 797758 ratings\n",
      "Test data set has 202451 ratings\n",
      "La BD has  3706  movies\n"
     ]
    }
   ],
   "source": [
    "#### Create a function that allows us to divide the dataset into:\n",
    "#### training and test\n",
    "def assign_to_set(df):\n",
    "    sampled_ids = np.random.choice(df.index,\n",
    "                                   size=np.int64(np.ceil(df.index.size * 0.2)),\n",
    "                                   replace=False)\n",
    "    df.loc[sampled_ids, 'for_testing'] = True\n",
    "    return df\n",
    "\n",
    "def create_train_test(data,key = 'user_id'):\n",
    "    data['for_testing'] = False\n",
    "    grouped = data.groupby(key, group_keys=False).apply(assign_to_set)\n",
    "    # dataframe used to train our model\n",
    "    data_train = data[grouped.for_testing == False]\n",
    "    # dataframe used to evaluate our model\n",
    "    data_test = data[grouped.for_testing == True]\n",
    "    return data_train, data_test\n",
    "\n",
    "data_train, data_test =  create_train_test(data)\n",
    "print(data_train.shape, data_test.shape)\n",
    "\n",
    "print(\"Training data_set has \"+ str(data_train.shape[0]) +\" ratings\")\n",
    "print(\"Test data set has \"+ str(data_test.shape[0]) +\" ratings\")\n",
    "print(\"La BD has \", data.movie_id.nunique(), \" movies\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### How can we compute user similarities?\n",
    "Let's look first for the common seen movies by the users "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of common movies 4 \n",
      "\n",
      "                                        title  rating\n",
      "0      One Flew Over the Cuckoo's Nest (1975)       5\n",
      "21674                    Pleasantville (1998)       3\n",
      "52255              Saving Private Ryan (1998)       5\n",
      "59344               Dead Poets Society (1989)       4\n",
      "                                        title  rating\n",
      "1      One Flew Over the Cuckoo's Nest (1975)       5\n",
      "21675                    Pleasantville (1998)       3\n",
      "52256              Saving Private Ryan (1998)       4\n",
      "59345               Dead Poets Society (1989)       5\n"
     ]
    }
   ],
   "source": [
    "user_id_1, user_id_2 = 1,2\n",
    "# dataframe with the data from selected users\n",
    "data_user_1 = data_train[data_train.user_id==user_id_1]\n",
    "data_user_2 = data_train[data_train.user_id==user_id_2]\n",
    "\n",
    "# We first compute the set of common movies\n",
    "common_movies = set(data_user_1.movie_id).intersection(data_user_2.movie_id)\n",
    "print(\"\\nNumber of common movies\",len(common_movies),'\\n')\n",
    "\n",
    "# creat the subdataframe with only with the common movies\n",
    "mask = (data_user_1.movie_id.isin(common_movies))\n",
    "data_user_1 = data_user_1[mask]\n",
    "print(data_user_1[['title','rating']].head())\n",
    "\n",
    "mask = (data_user_2.movie_id.isin(common_movies))\n",
    "data_user_2 = data_user_2[mask]\n",
    "print(data_user_2[['title','rating']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0    5\n",
       " 1    3\n",
       " 2    5\n",
       " 3    4\n",
       " Name: rating_x, dtype: int64,\n",
       " 0    5\n",
       " 1    3\n",
       " 2    4\n",
       " 3    5\n",
       " Name: rating_y, dtype: int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = pd.merge(data_user_1[['user_id','movie_id','rating']],data_user_2[['user_id','movie_id','rating']],on='movie_id')\n",
    "\n",
    "r.rating_x,r.rating_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6>Let's define a function to compute the users similarity </h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.32732683535398854\n",
      "0.2402530733520421\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import pearsonr\n",
    "from scipy.spatial.distance import euclidean\n",
    "\n",
    "# Returns a distance-based similarity score for person1 and person2\n",
    "def SimEuclid(DataFrame,User1,User2,min_common_items=1):\n",
    "    # GET MOVIES OF USER1\n",
    "    movies_user1=DataFrame[DataFrame['user_id'] ==User1 ]\n",
    "    # GET MOVIES OF USER2\n",
    "    movies_user2=DataFrame[DataFrame['user_id'] ==User2 ]\n",
    "    \n",
    "    # FIND SHARED FILMS\n",
    "    rep=pd.merge(movies_user1 ,movies_user2,on='movie_id')    \n",
    "    if len(rep)<2:\n",
    "        return 0\n",
    "    if(len(rep)<min_common_items):\n",
    "        return 0\n",
    "    #return distEuclid(rep['rating_x'],rep['rating_y']) \n",
    "    return 1.0/(1.0+euclidean(rep['rating_x'],rep['rating_y'])) \n",
    "\n",
    "# Returns a pearsonCorrealation-based similarity score for person1 and person2\n",
    "def SimPearson(DataFrame,User1,User2,min_common_items=1):\n",
    "    # GET MOVIES OF USER1\n",
    "    movies_user1=DataFrame[DataFrame['user_id'] ==User1 ]\n",
    "    # GET MOVIES OF USER2\n",
    "    movies_user2=DataFrame[DataFrame['user_id'] ==User2 ]\n",
    "    \n",
    "    # FIND SHARED FILMS\n",
    "    rep=pd.merge(movies_user1 ,movies_user2,on='movie_id',)\n",
    "    if len(rep)<2:\n",
    "        return 0    \n",
    "    if(len(rep)<min_common_items):\n",
    "        return 0    \n",
    "    res=pearsonr(rep['rating_x'],rep['rating_y'])[0]\n",
    "    if(np.isnan(res)):\n",
    "        return 0\n",
    "    return res\n",
    "\n",
    "print(SimPearson(data_train,1,3))\n",
    "print(SimEuclid(data_train,1,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Let's build a Recommender System</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def evaluate(estimate_f,data_train,data_test):\n",
    "    \"\"\" RMSE-based predictive performance evaluation with pandas. \"\"\"\n",
    "    ids_to_estimate = zip(data_test.user_id, data_test.movie_id)\n",
    "    estimated = np.array([estimate_f(u,i) if u in data_train.user_id else 3 for (u,i) in ids_to_estimate ])\n",
    "    real = data_test.rating.values\n",
    "    \n",
    "    return compute_rmse(estimated, real)\n",
    "\n",
    "\n",
    "def evaluate_algorithm_top(test, recommender_object, at=5, thr_relevant = 4):\n",
    "    \n",
    "    cumulative_precision = 0.0\n",
    "    cumulative_recall = 0.0\n",
    "    cumulative_AP = 0.0\n",
    "    \n",
    "    num_eval = 0\n",
    "\n",
    "\n",
    "    for user_id in tqdm(test.user_id.unique()):\n",
    "\n",
    "        relevant_items = test[(test.user_id==user_id )&( test.rating>=thr_relevant)].movie_id.values\n",
    "        \n",
    "        if len(relevant_items)>0:\n",
    "            \n",
    "            recommended_items = recommender_object.predict_top(user_id, at=at)\n",
    "            num_eval+=1\n",
    "\n",
    "            cumulative_precision += precision(recommended_items, relevant_items)\n",
    "            cumulative_recall += recall(recommended_items, relevant_items)\n",
    "            cumulative_AP += AP(recommended_items, relevant_items)\n",
    "            \n",
    "    cumulative_precision /= num_eval\n",
    "    cumulative_recall /= num_eval\n",
    "    MAP = cumulative_AP / num_eval\n",
    "    \n",
    "    print(\"Recommender results are: Precision = {:.4f}, Recall = {:.4f}, MAP = {:.4f}\".format(\n",
    "        cumulative_precision, cumulative_recall, MAP)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's create a small dataset in order to reduce the computation cost and speedup the calculus in the class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now this dataset contains 12900 samples\n",
      "#Training samples =  10281\n",
      "#Test samples =  2619\n",
      "#Users = 99\n",
      "#Movies = 2317\n"
     ]
    }
   ],
   "source": [
    "dataSmall = data[data['user_id']<100].copy() # get only data from 100 users\n",
    "print(\"Now this dataset contains\", dataSmall.shape[0],'samples')\n",
    "\n",
    "dataSmall_train, dataSmall_test =  create_train_test(dataSmall)\n",
    "\n",
    "print(\"#Training samples = \",dataSmall_train.shape[0])\n",
    "print(\"#Test samples = \",dataSmall_test.shape[0])\n",
    "print('#Users =', dataSmall.user_id.nunique())\n",
    "print('#Movies =',dataSmall.movie_id.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomRecommender():\n",
    "\n",
    "    def fit(self, train):\n",
    "        self.items = train.title.unique()\n",
    "    \n",
    "    \n",
    "    def predict_score(self, user_id, movie_id):\n",
    "        '''Given a user_id and item_id predict it score'''\n",
    "        return np.random.uniform(1,5)\n",
    "    \n",
    "    def predict_top(self, user_id, at=5):\n",
    "        recommended_items = np.random.choice(self.items, at)\n",
    "\n",
    "        return recommended_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.5195637922856604"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recoRND = RandomRecommender()\n",
    "recoRND.fit(dataSmall_train)\n",
    "recoRND.predict_score(user_id=2,movie_id=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for Collaborative Recomender: 1.393455112851323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/99 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [00:00<00:00, 441.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommender results are: Precision = 0.0000, Recall = 0.0000, MAP = 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print('RMSE for Collaborative Recomender: %s' % evaluate(recoRND.predict_score,dataSmall_train,dataSmall_test))\n",
    "evaluate_algorithm_top(dataSmall_test, recoRND)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm # conda install -y tqdm\n",
    "\n",
    "class CollaborativeFiltering():\n",
    "    \"\"\" Collaborative filtering using a custom sim(u,u'). \"\"\"\n",
    "    \n",
    "    def __init__(self, similarity=SimPearson):\n",
    "        \"\"\" Constructor \"\"\"\n",
    "        self.sim_method=similarity# Gets recommendations for a person by using a weighted average\n",
    "        self.sim = {}\n",
    "        \n",
    "    def fit(self,train):\n",
    "        \"\"\" Prepare data structures for estimation. Similarity matrix for users \"\"\"\n",
    "        print(\"Learning...\")\n",
    "        self.train = train\n",
    "        allUsers=set(self.train['user_id'])\n",
    "        \n",
    "        for person1 in tqdm(allUsers):\n",
    "            self.sim.setdefault(person1, {})\n",
    "            a=self.train[self.train['user_id']==person1][['movie_id']]\n",
    "            data_reduced=pd.merge(self.train,a,on='movie_id') # reduce time complexity\n",
    "            for person2 in allUsers:\n",
    "                if person1==person2: continue\n",
    "                self.sim.setdefault(person2, {})\n",
    "                if(person1 in self.sim[person2]):continue # since is a simetric matrix\n",
    "                sim=self.sim_method(data_reduced,person1,person2)\n",
    "                if(sim<0):\n",
    "                    self.sim[person1][person2]=0\n",
    "                    self.sim[person2][person1]=0\n",
    "                else:\n",
    "                    self.sim[person1][person2]=sim\n",
    "                    self.sim[person2][person1]=sim\n",
    "                \n",
    "    def predict_score(self, user_id, movie_id):\n",
    "        totals={}\n",
    "        movie_users=self.train[self.train['movie_id'] ==movie_id]\n",
    "        rating_num=0.0\n",
    "        rating_den=0.0\n",
    "        allUsers=set(movie_users['user_id'])\n",
    "        for other in allUsers:\n",
    "            if user_id==other: continue \n",
    "            rating_num += self.sim[user_id][other] * float(movie_users[movie_users['user_id']==other]['rating'])\n",
    "            rating_den += self.sim[user_id][other]\n",
    "        if rating_den==0: \n",
    "            if self.train.rating[self.train['movie_id']==movie_id].mean()>0:\n",
    "                # return the mean movie rating if there is no similar for the computation\n",
    "                return self.train.rating[self.train['movie_id']==movie_id].mean()\n",
    "            else:\n",
    "                # else return mean user rating \n",
    "                return self.train.rating[self.train['user_id']==user_id].mean()\n",
    "        return rating_num/rating_den\n",
    "    \n",
    "    def predict_top(self, user_id, at=5, remove_seen=True):\n",
    "        '''Given a user_id predict its top AT items'''\n",
    "        seen_items = self.train[self.train.user_id==user_id].movie_id.values\n",
    "        unseen_items = set(self.train.movie_id.values) - set(seen_items)\n",
    "\n",
    "        predictions = [(item_id,self.predict_score(user_id,item_id)) for item_id in unseen_items]\n",
    "\n",
    "        sorted_predictions = sorted(predictions, key=lambda x: x[1],reverse = True)[:at]\n",
    "        return [i[0] for i in sorted_predictions]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                    | 0/99 [00:00<?, ?it/s]/Users/santisegui/opt/anaconda3/lib/python3.8/site-packages/scipy/stats/stats.py:4023: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n",
      "100%|███████████████████████████████████████████| 99/99 [00:11<00:00,  8.77it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4.316831208488067"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reco = CollaborativeFiltering()\n",
    "reco.fit(dataSmall_train)\n",
    "reco.predict_score(user_id=2,movie_id=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for Collaborative Recomender: 1.2435603226980787\n"
     ]
    }
   ],
   "source": [
    "print('RMSE for Collaborative Recomender: %s' % evaluate(reco.predict_score,dataSmall_train,dataSmall_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 99/99 [04:48<00:00,  2.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommender results are: Precision = 0.0000, Recall = 0.0000, MAP = 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_algorithm_top(dataSmall_test, reco)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EXERCISE 1\n",
    "Modify the Recomender System using as a prediction function the following equation:\n",
    "$$pred(a,p) = \\bar{r_a} + \\frac{\\sum_{b \\in N}{sim(a,b)*(r_{b,p}-\\bar{r_b})}}{\\sum_{b \\in N}{sim(a,b)}}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <b>EXERCISE 2:</b><br>\n",
    "Modify the recomender system from the previous exercice, with one that in order to estimate the score of a movie B for the user A only uses the subset of the N most similar users to user A. Define N as a parameter of the Recommender.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class  = \"alert alert-success\"><b>EXERCISE 3</b><p>\n",
    "Modify the similarity function with the following:\n",
    "$$new\\_sim(a,b) = sim(a,b) * \\frac{min(50,|P_{ab}|)}{50} $$\n",
    "where $|P_{ab}|$ is the number of common items with user $a$ and user $b$\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class  = \"alert alert-success\"><b>EXERCISE 4</b><p>\n",
    "Is there a set of users where the systems work better than with othes users?\n",
    "Does it depend on the number of rating per user? Explain your conclusions and try to alleviate this problem\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class  = \"alert alert-success\"><b>EXERCISE 5</b><p>\n",
    "Create a Item-Based recomender system and compare its performance agains the User-Based\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

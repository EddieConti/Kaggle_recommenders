{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "097cf83b-a6c9-451f-bd15-a2ccb0e38e26",
      "metadata": {
        "tags": [],
        "id": "097cf83b-a6c9-451f-bd15-a2ccb0e38e26"
      },
      "source": [
        "# Lesson 6b: Factorization Machines with Keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a9c7db2e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "a9c7db2e",
        "outputId": "a2a0e6fd-f54e-4336-ffb8-d13249ede0fb"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>.container { width:100% !important; }</style>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from IPython.core.display import display, HTML\n",
        "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a780bcb6-7381-4a5d-a066-87db5561761a",
      "metadata": {
        "id": "a780bcb6-7381-4a5d-a066-87db5561761a"
      },
      "source": [
        "# Factorization Machine Model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!mkdir -p /content/drive/MyDrive/Kaggle_competition/model\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "09pi5tO26qB8",
        "outputId": "6b29971f-f12b-47e2-b110-ee41c09c2cac"
      },
      "id": "09pi5tO26qB8",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "cf63b59a-5d9f-456a-ac66-3c0252303657",
      "metadata": {
        "id": "cf63b59a-5d9f-456a-ac66-3c0252303657"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from pathlib import Path\n",
        "from zipfile import ZipFile\n",
        "from tensorflow.keras import regularizers\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "d2b023dd-09b4-4e7e-87e8-19f4c461a6d8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 657
        },
        "id": "d2b023dd-09b4-4e7e-87e8-19f4c461a6d8",
        "outputId": "6db3540d-340a-4149-d20b-9e59973dd44b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from http://files.grouplens.org/datasets/movielens/ml-1m.zip\n",
            "5917549/5917549 [==============================] - 2s 0us/step\n",
            "Extracting all the files now...\n",
            "Done!\n",
            "====== rating.dat ======\n",
            "   uid   mid  rating  timestamp\n",
            "0    1  1193       5  978300760\n",
            "1    1   661       3  978302109\n",
            "2    1   914       3  978301968\n",
            "3    1  3408       4  978300275\n",
            "4    1  2355       5  978824291\n",
            "===== movies.dat ======\n",
            "   mid                          movie_name                   movie_genre\n",
            "0    1                    Toy Story (1995)   Animation|Children's|Comedy\n",
            "1    2                      Jumanji (1995)  Adventure|Children's|Fantasy\n",
            "2    3             Grumpier Old Men (1995)                Comedy|Romance\n",
            "3    4            Waiting to Exhale (1995)                  Comedy|Drama\n",
            "4    5  Father of the Bride Part II (1995)                        Comedy\n",
            "====== users.dat ======\n",
            "   uid user_fea1  user_fea2  user_fea3 user_fea4\n",
            "0    1         F          1         10     48067\n",
            "1    2         M         56         16     70072\n",
            "2    3         M         25         15     55117\n",
            "3    4         M         45          7     02460\n",
            "4    5         M         25         20     55455\n",
            "====== preprocessed data =======\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   uid   mid  rating  timestamp user_fea1  user_fea2  user_fea3 user_fea4  \\\n",
              "0    1  1193       5  978300760         F          1         10     48067   \n",
              "1    2  1193       5  978298413         M         56         16     70072   \n",
              "2   12  1193       4  978220179         M         25         12     32793   \n",
              "3   15  1193       4  978199279         M         25          7     22903   \n",
              "4   17  1193       5  978158471         M         50          1     95350   \n",
              "\n",
              "                               movie_name movie_genre  \n",
              "0  One Flew Over the Cuckoo's Nest (1975)   [1, 0, 0]  \n",
              "1  One Flew Over the Cuckoo's Nest (1975)   [1, 0, 0]  \n",
              "2  One Flew Over the Cuckoo's Nest (1975)   [1, 0, 0]  \n",
              "3  One Flew Over the Cuckoo's Nest (1975)   [1, 0, 0]  \n",
              "4  One Flew Over the Cuckoo's Nest (1975)   [1, 0, 0]  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fc1c2643-99f5-4bfe-830f-5a4179189ea0\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>uid</th>\n",
              "      <th>mid</th>\n",
              "      <th>rating</th>\n",
              "      <th>timestamp</th>\n",
              "      <th>user_fea1</th>\n",
              "      <th>user_fea2</th>\n",
              "      <th>user_fea3</th>\n",
              "      <th>user_fea4</th>\n",
              "      <th>movie_name</th>\n",
              "      <th>movie_genre</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1193</td>\n",
              "      <td>5</td>\n",
              "      <td>978300760</td>\n",
              "      <td>F</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>48067</td>\n",
              "      <td>One Flew Over the Cuckoo's Nest (1975)</td>\n",
              "      <td>[1, 0, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1193</td>\n",
              "      <td>5</td>\n",
              "      <td>978298413</td>\n",
              "      <td>M</td>\n",
              "      <td>56</td>\n",
              "      <td>16</td>\n",
              "      <td>70072</td>\n",
              "      <td>One Flew Over the Cuckoo's Nest (1975)</td>\n",
              "      <td>[1, 0, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>12</td>\n",
              "      <td>1193</td>\n",
              "      <td>4</td>\n",
              "      <td>978220179</td>\n",
              "      <td>M</td>\n",
              "      <td>25</td>\n",
              "      <td>12</td>\n",
              "      <td>32793</td>\n",
              "      <td>One Flew Over the Cuckoo's Nest (1975)</td>\n",
              "      <td>[1, 0, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>15</td>\n",
              "      <td>1193</td>\n",
              "      <td>4</td>\n",
              "      <td>978199279</td>\n",
              "      <td>M</td>\n",
              "      <td>25</td>\n",
              "      <td>7</td>\n",
              "      <td>22903</td>\n",
              "      <td>One Flew Over the Cuckoo's Nest (1975)</td>\n",
              "      <td>[1, 0, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>17</td>\n",
              "      <td>1193</td>\n",
              "      <td>5</td>\n",
              "      <td>978158471</td>\n",
              "      <td>M</td>\n",
              "      <td>50</td>\n",
              "      <td>1</td>\n",
              "      <td>95350</td>\n",
              "      <td>One Flew Over the Cuckoo's Nest (1975)</td>\n",
              "      <td>[1, 0, 0]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fc1c2643-99f5-4bfe-830f-5a4179189ea0')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-fc1c2643-99f5-4bfe-830f-5a4179189ea0 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-fc1c2643-99f5-4bfe-830f-5a4179189ea0');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-4c27e9ea-f81c-4484-baaf-41f21aae66de\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4c27e9ea-f81c-4484-baaf-41f21aae66de')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-4c27e9ea-f81c-4484-baaf-41f21aae66de button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "ratings"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "## FACTORIZATION MODELS\n",
        "\n",
        "# Download the actual data from http://files.grouplens.org/datasets/movielens/ml-latest-small.zip\"\n",
        "# Use the ratings.csv file\n",
        "movielens_data_file_url = (\n",
        "    \"http://files.grouplens.org/datasets/movielens/ml-1m.zip\"\n",
        ")\n",
        "movielens_zipped_file = keras.utils.get_file(\n",
        "    \"ml-1m.zip\", movielens_data_file_url, extract=False\n",
        ")\n",
        "keras_datasets_path = Path(movielens_zipped_file).parents[0]\n",
        "movielens_dir = keras_datasets_path / \"ml-1m\"\n",
        "\n",
        "# Only extract the data the first time the script is run.\n",
        "if not movielens_dir.exists():\n",
        "    with ZipFile(movielens_zipped_file, \"r\") as zip:\n",
        "        # Extract files\n",
        "        print(\"Extracting all the files now...\")\n",
        "        zip.extractall(path=keras_datasets_path)\n",
        "        print(\"Done!\")\n",
        "\n",
        "\n",
        "def load_ratings(movielens_dir):\n",
        "    COL_NAME = ['uid','mid','rating','timestamp']\n",
        "    df = pd.read_csv(movielens_dir / 'ratings.dat',sep='::', header=None, engine='python', names=COL_NAME)\n",
        "    return df\n",
        "\n",
        "def load_movies(movielens_dir):\n",
        "    COL_NAME = ['mid','movie_name','movie_genre']\n",
        "    df = pd.read_csv(movielens_dir / 'movies.dat',sep='::', header=None, engine='python', names=COL_NAME, encoding='latin-1')\n",
        "    return df\n",
        "\n",
        "def load_users(movielens_dir):\n",
        "    COL_NAME = ['uid','user_fea1','user_fea2','user_fea3','user_fea4']\n",
        "    df = pd.read_csv(movielens_dir / 'users.dat',sep='::', header=None, engine='python', names=COL_NAME)\n",
        "    return df\n",
        "\n",
        "def text2seq(text, n_genre):\n",
        "    \"\"\" using tokenizer to encoded the multi-level categorical feature\n",
        "    \"\"\"\n",
        "    tokenizer = Tokenizer(lower=True, split='|',filters='', num_words=n_genre)\n",
        "    tokenizer.fit_on_texts(text)\n",
        "    seq = tokenizer.texts_to_sequences(text)\n",
        "    seq = pad_sequences(seq, maxlen=3,padding='post')\n",
        "    return seq\n",
        "\n",
        "n_genre = 15\n",
        "\n",
        "\n",
        "ratings = load_ratings(movielens_dir)\n",
        "movies = load_movies(movielens_dir)\n",
        "users = load_users(movielens_dir)\n",
        "\n",
        "\n",
        "print(\"====== rating.dat ======\")\n",
        "print(ratings.head())\n",
        "print(\"===== movies.dat ======\")\n",
        "print(movies.head())\n",
        "print(\"====== users.dat ======\")\n",
        "print(users.head())\n",
        "\n",
        "movies['movie_genre'] = text2seq(movies.movie_genre.values, n_genre=n_genre).tolist()\n",
        "\n",
        "ratings = pd.merge(pd.merge(ratings, users), movies)\n",
        "\n",
        "print(\"====== preprocessed data =======\")\n",
        "ratings.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Let us extract some additional features in order to have a better insight"
      ],
      "metadata": {
        "id": "AdX7QLFhueGL"
      },
      "id": "AdX7QLFhueGL"
    },
    {
      "cell_type": "code",
      "source": [
        "# We extract from the dataset some information: we extract the year of the movie (if missing we replace with the mean)\n",
        "# We extract the last movie seen from the user, the amount of movie saw, we convert the sex in 1 and 0, we normalize the year\n"
      ],
      "metadata": {
        "id": "ZOY3ChBeui9B"
      },
      "id": "ZOY3ChBeui9B",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "normal_transf= StandardScaler()\n",
        "def preprocessing_and_extracting(df):\n",
        "\n",
        "    df['user_fea1'] = df['user_fea1'].replace('M',1)\n",
        "    df['user_fea1'] = df['user_fea1'].replace('F',0)\n",
        "    y = re.compile(r'\\((\\d{4})\\)')\n",
        "    years = [int(y.findall(title)[0]) if y.findall(title) else None for title in df['movie_name']]\n",
        "    mean_year = sum(year for year in years if year is not None) / len([year for year in years if year is not None]) # we take a mean year to impute for missing years\n",
        "    df['year'] = [year if year is not None else int(mean_year) for year in years]\n",
        "    # df['last_seen']=df['timestamp'].apply(lambda x: 1 if x in set_of_timestamp else 0)\n",
        "    df_grouped = df.groupby('uid').agg({'timestamp': 'max'}).reset_index()\n",
        "    set_of_timestamp=df_grouped['timestamp'].values\n",
        "    df['last_seen'] = df['timestamp'].isin(set_of_timestamp).astype(int) # we mark the last movie\n",
        "    mean_ratings = df.groupby('uid')['rating'].transform('mean')\n",
        "    df['weight_rating'] = np.where(df['rating'] > mean_ratings, 1, -1)  # we mark with 1 movies with high rating and -1 the others\n",
        "\n",
        "    df['age_difference'] = abs(df['user_fea2'] - (2003 - df['year']))\n",
        "\n",
        "    df['user_fea2'] = (df['user_fea2']-df['user_fea2'].mean())/(df['user_fea2'].std()) # normalizing the year\n",
        "\n",
        "    max_timestamp= ratings.groupby('uid')['timestamp'].transform('max')\n",
        "    df['diff_timestamp'] = df['timestamp'] - max_timestamp\n",
        "    df['count_ratings']= ratings.groupby('uid')['rating'].transform('count').values\n",
        "\n",
        "    #NORMALIZATION OF NUMERICAL VALUES\n",
        "\n",
        "    df['age_difference'] = normal_transf.fit_transform(df['age_difference'].values.reshape(-1, 1))\n",
        "\n",
        "    df['diff_timestamp'] = normal_transf.fit_transform(df['diff_timestamp'].values.reshape(-1, 1))\n",
        "    df['count_ratings'] = normal_transf.fit_transform(df['count_ratings'].values.reshape(-1, 1))\n",
        "    df['user_fea3'] = normal_transf.fit_transform(df['user_fea3'].values.reshape(-1, 1))\n",
        "\n",
        "\n",
        "    return df\n",
        "\n"
      ],
      "metadata": {
        "id": "_Z5yabniyUZw"
      },
      "id": "_Z5yabniyUZw",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ratings=preprocessing_and_extracting(ratings)"
      ],
      "metadata": {
        "id": "IjVtuGiNf5b-"
      },
      "id": "IjVtuGiNf5b-",
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "cbee0fe4-cc01-42cc-81d0-34dd22299e1c",
      "metadata": {
        "id": "cbee0fe4-cc01-42cc-81d0-34dd22299e1c"
      },
      "source": [
        "## Define input layers\n",
        "The dataset contains a **numeric** and **categerical** features, they need to be treated differently.\n",
        "\n",
        "* **numeric features** can be concatenated to inputs, with shape (None, num_of_numeric)\n",
        "* **categorical features** can be encoded individually to inputs, with shape (None, 1) each."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Testo del titolo predefinito\n",
        "import tensorflow.keras.backend as K\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import *\n",
        "\n",
        "def define_input_layers():\n",
        "    # numerical features\n",
        "    fea3_input = Input((1,), name='input_fea3')\n",
        "    fea2_input = Input((1,), name='input_fea2')\n",
        "    year_input = Input((1,), name='input_year')\n",
        "    #weight_rating_input = Input((1,), name='input_weight_rating')\n",
        "    age_difference_input = Input((1,), name='input_age_difference')\n",
        "     #diff_timestamp_input = Input((1,), name='input_diff_timestamp')\n",
        "    #count_ratings_input = Input((1,), name='input_count_ratings')\n",
        "\n",
        "    num_inputs = [fea3_input, fea2_input, year_input, age_difference_input]\n",
        "\n",
        "    # single level categorical features\n",
        "    uid_input = Input((1,), name='input_uid')  # user_id\n",
        "    last_seen_input = Input((1,), name='input_last_seen')\n",
        "    mid_input = Input((1,), name='input_mid')  # movie_id\n",
        "    cat_sl_inputs = [uid_input, last_seen_input, mid_input]\n",
        "\n",
        "    # multi level categorical features (with 3 genres at most)\n",
        "    genre_input = Input((3,), name='input_genre')\n",
        "    cat_ml_inputs = [genre_input]\n",
        "\n",
        "    inputs = num_inputs + cat_sl_inputs + cat_ml_inputs\n",
        "\n",
        "    return inputs\n",
        "\n",
        "inputs = define_input_layers()\n"
      ],
      "metadata": {
        "id": "V0WTTFbV9LF_"
      },
      "id": "V0WTTFbV9LF_",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "e6174677-bd59-4960-8050-bc1d3aadd383",
      "metadata": {
        "id": "e6174677-bd59-4960-8050-bc1d3aadd383"
      },
      "source": [
        "## 1st order factorization machines\n",
        "1st order will require features to map to a scalar. so for:\n",
        "\n",
        "* numeric feature: a dense layer will convert tensor to shape (None,1)\n",
        "* categorical feature: a embedding layer will convert tensor to shape (None,1,1) and then reshape layer to reshape to (None,1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "f3802ab7-d36f-4a89-848b-8945c579e9c9",
      "metadata": {
        "id": "f3802ab7-d36f-4a89-848b-8945c579e9c9"
      },
      "outputs": [],
      "source": [
        "def Tensor_Mean_Pooling(name = 'mean_pooling', keepdims = False):\n",
        "    return Lambda(lambda x: K.mean(x, axis = 1, keepdims=keepdims), name = name)\n",
        "\n",
        "def fm_1d(inputs, n_uid, n_mid, n_genre, reg_weight):\n",
        "\n",
        "    # user feat3 + user embedding + movie embedding + genre embedding\n",
        "    fea3_input, fea2_input, year_input, age_difference_input, uid_input, last_seen_input, mid_input, genre_input = inputs\n",
        "\n",
        "    # all tensors are reshape to (None, 1)\n",
        "    num_dense_1d = [Dense(1, name='num_dense_1d_fea3')(fea3_input),\n",
        "                    Dense(1, name='num_dense_1d_fea2')(fea2_input),\n",
        "                    Dense(1, name='num_dense_1d_year')(year_input),\n",
        "                    #Dense(1, name='num_dense_1d_last_seen')(last_seen_input),\n",
        "                    #Dense(1, name='num_dense_1d_weight_rating')(weight_rating_input),\n",
        "                    Dense(1, name='num_dense_1d_age_difference')(age_difference_input)]\n",
        "                    #Dense(1, name='num_dense_1d_diff_timestamp')(diff_timestamp_input),\n",
        "                    #Dense(1, name='num_dense_1d_count_ratings')(count_ratings_input)]\n",
        "\n",
        "    cat_sl_embed_1d = [Embedding(n_uid + 1, 1, name = 'cat_embed_1d_uid',  embeddings_regularizer=regularizers.l2(reg_weight))(uid_input),\n",
        "                       Embedding(n_uid + 1, 1, name='cat_embed_1d_lastseen',  embeddings_regularizer=regularizers.l2(reg_weight))(last_seen_input),\n",
        "                       Embedding(n_mid + 1, 1, name = 'cat_embed_1d_mid',  embeddings_regularizer=regularizers.l2(reg_weight))(mid_input)]\n",
        "    cat_ml_embed_1d = [Embedding(n_genre + 1, 1, mask_zero=True, name = 'cat_embed_1d_genre', embeddings_regularizer=regularizers.l2(reg_weight))(genre_input)]\n",
        "\n",
        "    cat_sl_embed_1d = [Reshape((1,))(i) for i in cat_sl_embed_1d]\n",
        "    cat_ml_embed_1d = [Tensor_Mean_Pooling(name = 'embed_1d_mean')(i) for i in cat_ml_embed_1d]\n",
        "\n",
        "    # add all tensors\n",
        "    y_fm_1d = Add(name = 'fm_1d_output')(num_dense_1d + cat_sl_embed_1d + cat_ml_embed_1d)\n",
        "\n",
        "    return y_fm_1d\n",
        "\n",
        "#y_1d = fm_1d(inputs, 10, 10, 10)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "71f9acdd-f8b3-4fcc-aa63-38b3853c8965",
      "metadata": {
        "id": "71f9acdd-f8b3-4fcc-aa63-38b3853c8965"
      },
      "source": [
        "## 2nd order factorization machines\n",
        "In 2nd order FM, each feature is map to shape (None, 1, k) and then stack to concat_embed_2d layer with shape (None, p, k).\n",
        "k - matrix factorization latent dimension, p is feature dimension.\n",
        "\n",
        "the calculation of interaction terms can be simplified, using\n",
        "\\begin{equation*} \\sum{x_ix_j} = \\frac{1}{2} \\left((\\sum{x})^2 - \\sum({x}^2)\\right) \\end{equation*}\n",
        "\n",
        "Hence, the sum of 2nd order interactions = square of sum of concat_embed_2d - sum of squared concat_embed_2d in p dimension, the resulting tensor will have a shape (None, k)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "5e3ff7ec-d2d4-489b-a3d5-48d0270757a9",
      "metadata": {
        "id": "5e3ff7ec-d2d4-489b-a3d5-48d0270757a9"
      },
      "outputs": [],
      "source": [
        "def fm_2d(inputs, n_uid, n_mid, n_genre, k, reg_weight):\n",
        "\n",
        "    fea3_input, fea2_input, year_input, age_difference_input, uid_input, last_seen_input, mid_input, genre_input = inputs\n",
        "\n",
        "    num_dense_2d = [Dense(k, name='num_dense_2d_fea3')(fea3_input), # Shape (none,1)\n",
        "                    Dense(k, name='num_dense_2d_fea2')(fea2_input),\n",
        "                    Dense(k, name='num_dense_2d_year')(year_input),\n",
        "                    #Dense(k, name='num_dense_2d_last_seen')(last_seen_input),\n",
        "                    #Dense(k, name='num_dense_2d_weight_rating')(weight_rating_input),\n",
        "                    Dense(k, name='num_dense_2d_age_difference')(age_difference_input)]\n",
        "                    #Dense(k, name='num_dense_2d_diff_timestamp')(diff_timestamp_input),\n",
        "                    #Dense(k, name='num_dense_2d_count_ratings')(count_ratings_input)]\n",
        "\n",
        "    num_dense_2d = [Reshape((1, k))(i) for i in num_dense_2d] #shape (None, 1 , k)\n",
        "\n",
        "\n",
        "    cat_sl_embed_2d = [Embedding(n_uid + 1, k, name = 'cat_embed_2d_uid',  embeddings_regularizer=regularizers.l2(reg_weight))(uid_input),\n",
        "                       Embedding(n_uid + 1, k, name='cat_embed_2d_lastseen', embeddings_regularizer=regularizers.l2(reg_weight))(last_seen_input),\n",
        "                       Embedding(n_mid + 1, k, name = 'cat_embed_2d_mid',  embeddings_regularizer=regularizers.l2(reg_weight))(mid_input)] # shape (None, 1, k)\n",
        "\n",
        "    cat_ml_embed_2d = [Embedding(n_genre + 1, k, name = 'cat_embed_2d_genre',embeddings_regularizer=regularizers.l2(reg_weight))(genre_input)] # shape (None, 3, k)\n",
        "    cat_ml_embed_2d = [Tensor_Mean_Pooling(name = 'cat_embed_2d_genure_mean', keepdims=True)(i) for i in cat_ml_embed_2d] # shape (None, 1, k)\n",
        "\n",
        "    # concatenate all 2d embed layers => (None, ?, k)\n",
        "    embed_2d = Concatenate(axis=1, name = 'concat_embed_2d')(num_dense_2d + cat_sl_embed_2d + cat_ml_embed_2d)\n",
        "\n",
        "    # calcuate the interactions by simplication\n",
        "    # sum of (x1*x2) = sum of (0.5*[(xi)^2 - (xi^2)])\n",
        "    tensor_sum = Lambda(lambda x: K.sum(x, axis = 1), name = 'sum_of_tensors')\n",
        "    tensor_square = Lambda(lambda x: K.square(x), name = 'square_of_tensors')\n",
        "\n",
        "    sum_of_embed = tensor_sum(embed_2d)\n",
        "    square_of_embed = tensor_square(embed_2d)\n",
        "\n",
        "    square_of_sum = Multiply()([sum_of_embed, sum_of_embed])\n",
        "    sum_of_square = tensor_sum(square_of_embed)\n",
        "\n",
        "    sub = Subtract()([square_of_sum, sum_of_square])\n",
        "    sub = Lambda(lambda x: x*0.5)(sub)\n",
        "    y_fm_2d = Reshape((1,), name = 'fm_2d_output')(tensor_sum(sub))\n",
        "\n",
        "    return y_fm_2d, embed_2d"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eda1462c-5c6a-4119-b6c4-dd01234170e9",
      "metadata": {
        "id": "eda1462c-5c6a-4119-b6c4-dd01234170e9"
      },
      "source": [
        "## Put together"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "8cffd46d-ff84-4b19-b5d0-f0ef0860b3f0",
      "metadata": {
        "id": "8cffd46d-ff84-4b19-b5d0-f0ef0860b3f0"
      },
      "outputs": [],
      "source": [
        "def fm_model(n_uid, n_mid, n_genre, k, dnn_dr, reg_weight):\n",
        "\n",
        "    inputs = define_input_layers()\n",
        "\n",
        "    y_fm_1d = fm_1d(inputs, n_uid, n_mid, n_genre, reg_weight)\n",
        "    y_fm_2d, embed_2d = fm_2d(inputs, n_uid, n_mid, n_genre, k, reg_weight)\n",
        "\n",
        "\n",
        "    # combinded deep and fm parts\n",
        "    y = Concatenate()([y_fm_1d, y_fm_2d])\n",
        "    y = Dense(1, name = 'fm_output')(y)\n",
        "\n",
        "    fm_model_1d = Model(inputs, y_fm_1d)\n",
        "    fm_model_2d = Model(inputs, y_fm_2d)\n",
        "    fm_model = Model(inputs, y)\n",
        "\n",
        "    return fm_model_1d, fm_model_2d, fm_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "62f13199-0f81-46b5-9350-0d63bd330b51",
      "metadata": {
        "id": "62f13199-0f81-46b5-9350-0d63bd330b51"
      },
      "outputs": [],
      "source": [
        "params = {\n",
        "    'n_uid': ratings.uid.max(),\n",
        "    'n_mid': ratings.mid.max(),\n",
        "    'n_genre': 14,\n",
        "    'k': 30,\n",
        "    'dnn_dr': 0.5,\n",
        "    'reg_weight' : 0.01\n",
        "}\n",
        "\n",
        "fm_model_1d, fm_model_2d, fm_model = fm_model(**params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "08580b64-c5a5-4bc9-bc99-5202688f2145",
      "metadata": {
        "id": "08580b64-c5a5-4bc9-bc99-5202688f2145",
        "outputId": "fbe7e640-04b1-4734-d61c-36c2dba3aab2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'n_uid': 6040,\n",
              " 'n_mid': 3952,\n",
              " 'n_genre': 14,\n",
              " 'k': 20,\n",
              " 'dnn_dr': 0.5,\n",
              " 'reg_weight': 0.01}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "params"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c16feee8-07fa-45a7-ae43-d0aeb44166f0",
      "metadata": {
        "id": "c16feee8-07fa-45a7-ae43-d0aeb44166f0"
      },
      "source": [
        "## Prepare Data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dfa13ac7-6109-4256-90cc-16e45ddf20ad",
      "metadata": {
        "id": "dfa13ac7-6109-4256-90cc-16e45ddf20ad"
      },
      "source": [
        "### Split Data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train, val = train_test_split(ratings, test_size=0.2, random_state=7)"
      ],
      "metadata": {
        "id": "soA1C7XpB5-e"
      },
      "id": "soA1C7XpB5-e",
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "008f87b1-624f-4462-9ba8-c60e17190f47",
      "metadata": {
        "id": "008f87b1-624f-4462-9ba8-c60e17190f47"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def df2xy(ratings):\n",
        "    x = [ratings.user_fea2.values,\n",
        "         ratings.user_fea3.values,\n",
        "         ratings.year.values,\n",
        "         #ratings.weight_rating.values,\n",
        "         ratings.age_difference.values,\n",
        "         #ratings.diff_timestamp.values,\n",
        "         #ratings.count_ratings.values,\n",
        "         ratings.uid.values,\n",
        "         ratings.last_seen.values,\n",
        "         ratings.mid.values,\n",
        "         np.concatenate(ratings.movie_genre.values).reshape(-1, 3)]\n",
        "    y = ratings.rating.values\n",
        "    return x, y\n",
        "\n",
        "train_x, train_y = df2xy(train)\n",
        "valid_x, valid_y = df2xy(val)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dd32f9e8-448f-4500-9ff6-c6d335cc722b",
      "metadata": {
        "id": "dd32f9e8-448f-4500-9ff6-c6d335cc722b"
      },
      "source": [
        "## Train Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "8fffc746-7a5a-4b25-b1ed-8ac5c481f535",
      "metadata": {
        "id": "8fffc746-7a5a-4b25-b1ed-8ac5c481f535",
        "outputId": "9ed1bc64-3120-48cd-9076-bd03f1cb7bc1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "12503/12503 [==============================] - 117s 9ms/step - loss: 3355.4285 - val_loss: 32.7483\n",
            "Epoch 2/30\n",
            "12503/12503 [==============================] - 112s 9ms/step - loss: 10.6199 - val_loss: 2.9751\n",
            "Epoch 3/30\n",
            "12503/12503 [==============================] - 108s 9ms/step - loss: 1.8303 - val_loss: 1.7107\n",
            "Epoch 4/30\n",
            "12503/12503 [==============================] - 106s 8ms/step - loss: 1.1798 - val_loss: 1.1807\n",
            "Epoch 5/30\n",
            "12503/12503 [==============================] - 109s 9ms/step - loss: 1.0937 - val_loss: 1.0732\n",
            "Epoch 6/30\n",
            "12503/12503 [==============================] - 107s 9ms/step - loss: 1.0531 - val_loss: 1.0455\n",
            "Epoch 7/30\n",
            "12503/12503 [==============================] - 110s 9ms/step - loss: 1.0212 - val_loss: 1.0023\n",
            "Epoch 8/30\n",
            "12503/12503 [==============================] - 107s 9ms/step - loss: 1.0100 - val_loss: 0.9892\n",
            "Epoch 9/30\n",
            "12503/12503 [==============================] - 109s 9ms/step - loss: 1.0084 - val_loss: 1.0011\n",
            "Epoch 10/30\n",
            "12503/12503 [==============================] - 108s 9ms/step - loss: 1.0057 - val_loss: 1.0150\n",
            "Epoch 11/30\n",
            "12503/12503 [==============================] - 109s 9ms/step - loss: 1.0065 - val_loss: 1.0057\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "fm_model.compile(\n",
        "    loss=tf.keras.losses.MeanSquaredError(), optimizer=keras.optimizers.Adam(learning_rate=0.001)\n",
        ")\n",
        "\n",
        "model_checkpoint_path = '/content/drive/MyDrive/Kaggle_competition/model/deepfm_weights.best'\n",
        "\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=3)\n",
        "model_ckp = ModelCheckpoint(filepath=model_checkpoint_path,\n",
        "                            monitor='val_loss',\n",
        "                            save_weights_only=True,\n",
        "                            save_best_only=True)\n",
        "\n",
        "callbacks = [model_ckp, early_stop]\n",
        "\n",
        "train_history = fm_model.fit(train_x, train_y,\n",
        "                              epochs=30, batch_size=64,\n",
        "                              validation_data=(valid_x, valid_y),\n",
        "                              callbacks=callbacks)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Predictions"
      ],
      "metadata": {
        "id": "I6IdGSA1RF_L"
      },
      "id": "I6IdGSA1RF_L"
    },
    {
      "cell_type": "code",
      "source": [
        "test =pd.read_csv('/content/drive/My Drive/Kaggle_competition/kaggle_baseline.csv')\n",
        "\n",
        "# I have to produce the output for all of these users.\n"
      ],
      "metadata": {
        "id": "Q2jpgNFYRd1L"
      },
      "id": "Q2jpgNFYRd1L",
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_test_dataset(user_id, ratings):\n",
        "\n",
        "    movies_seen_by_user = ratings[ratings['uid'] == user_id]['mid'].unique()\n",
        "\n",
        "    all_movies_except_seen = ratings[~ratings['mid'].isin(movies_seen_by_user)]\n",
        "\n",
        "\n",
        "    test_dataset = pd.DataFrame({'uid': [user_id] * len(np.unique(all_movies_except_seen['mid'].values)),\n",
        "                                 'mid': np.unique(all_movies_except_seen['mid'].values)})\n",
        "\n",
        "    # We retrieve additional information\n",
        "    movies_info = ratings[~ratings['mid'].isin(movies_seen_by_user)][['mid', 'movie_name', 'movie_genre', 'timestamp']]\n",
        "\n",
        "    movies_info = movies_info.drop_duplicates(subset=['mid'])\n",
        "\n",
        "    test_dataset = pd.merge(test_dataset, movies_info, on='mid', how='left')\n",
        "\n",
        "    # Extract the year\n",
        "    test_dataset['year'] = ratings['movie_name'].str.extract(r'\\((\\d{4})\\)')\n",
        "    test_dataset['year'] = test_dataset['year'].astype(float)\n",
        "\n",
        "    # And fill missing year\n",
        "    mean_year = test_dataset['year'].mean()\n",
        "    test_dataset['year'] = test_dataset['year'].fillna(mean_year).astype(int)\n",
        "\n",
        "    # Calcola la feature last_seen\n",
        "    #last_seen = ratings.groupby('uid')['timestamp'].max().reset_index()\n",
        "    #last_seen.rename(columns={'timestamp': 'last_seen'}, inplace=True)\n",
        "    #test_dataset = pd.merge(test_dataset, last_seen, on='uid', how='left')\n",
        "    #test_dataset['last_seen'] = test_dataset['last_seen'].notnull().astype(int)\n",
        "    test_dataset['last_seen']= np.zeros(len(np.unique(all_movies_except_seen['mid'].values))) # Because he never saw these movies\n",
        "\n",
        "    # Retreive user_fea2 and user_fea3\n",
        "    test_dataset['user_fea2'] = ratings[ratings['uid'] == user_id]['user_fea2'].iloc[0]\n",
        "    test_dataset['user_fea3'] = ratings[ratings['uid'] == user_id]['user_fea3'].iloc[0]\n",
        "    test_dataset['user_fea2'] = (test_dataset['user_fea2']-test_dataset['user_fea2'].mean())/(test_dataset['user_fea2'].std()) # normalizing the year\n",
        "    test_dataset['age_difference'] = abs(test_dataset['user_fea2'] - (2003 - test_dataset['year']))\n",
        "\n",
        "\n",
        "\n",
        "    return test_dataset\n",
        "\n",
        "\n",
        "def get_prediction(test_dataset):\n",
        "\n",
        "    predictions = fm_model.predict(x = [test_dataset.user_fea2.values,\n",
        "                                  test_dataset.user_fea3.values,\n",
        "                                  test_dataset.year.values,\n",
        "                                  test_dataset.age_difference.values,\n",
        "                                  test_dataset.uid.values,\n",
        "                                  test_dataset.last_seen.values,\n",
        "                                  test_dataset.mid.values,\n",
        "                                  np.concatenate(test_dataset.movie_genre.values).reshape(-1, 3)])\n",
        "\n",
        "    # We add the prediction column\n",
        "    test_dataset['prediction'] = predictions\n",
        "\n",
        "    # Sort and then retreive the movie id\n",
        "    top_recommendations = test_dataset.sort_values(by='prediction', ascending=False).head(25)\n",
        "    recommended_movie_ids = top_recommendations['mid'].tolist()\n",
        "\n",
        "    return recommended_movie_ids\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "7W4l-m61XNzA"
      },
      "id": "7W4l-m61XNzA",
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the output\n",
        "import csv\n",
        "from tqdm import tqdm\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# open the file in the write mode\n",
        "with open('/content/drive/MyDrive/Kaggle_competition/solution.csv', 'w', encoding='UTF8') as f:\n",
        "    # create the csv writer\n",
        "    writer = csv.writer(f)\n",
        "    # write a row to the csv file\n",
        "    writer.writerow(['user_id', 'prediction'])\n",
        "\n",
        "    # iterate over unique user_ids with tqdm\n",
        "    for user_id in tqdm(test.user_id.unique(), desc=\"Processing Users\"):\n",
        "        test_set_user=create_test_dataset(user_id,ratings)\n",
        "        relevant_items = get_prediction(test_set_user)\n",
        "        list_relevants = ' '.join([str(elem) for elem in relevant_items])\n",
        "        writer.writerow([str(user_id), list_relevants])"
      ],
      "metadata": {
        "id": "5xMxix29rFt9"
      },
      "id": "5xMxix29rFt9",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.11"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
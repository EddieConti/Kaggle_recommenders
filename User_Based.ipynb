{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_rmse(y_pred, y_true):\n",
    "    \"\"\" Compute Root Mean Squared Error. \"\"\"\n",
    "    return np.sqrt(np.mean(np.power(y_pred - y_true, 2)))\n",
    "\n",
    "def precision(recommended_items, relevant_items):\n",
    "    is_relevant = np.in1d(recommended_items, relevant_items, assume_unique=True)\n",
    "    precision_score = np.sum(is_relevant, dtype=np.float32) / len(is_relevant)\n",
    "    \n",
    "    return precision_score\n",
    "\n",
    "def recall(recommended_items, relevant_items):  \n",
    "    is_relevant = np.in1d(recommended_items, relevant_items, assume_unique=True)\n",
    "    recall_score = np.sum(is_relevant, dtype=np.float32) / relevant_items.shape[0]\n",
    "    \n",
    "    return recall_score\n",
    "\n",
    "def AP(recommended_items, relevant_items):\n",
    "   \n",
    "    is_relevant = np.in1d(recommended_items, relevant_items, assume_unique=True)\n",
    "    # Cumulative sum: precision at 1, at 2, at 3 ...\n",
    "    p_at_k = is_relevant * np.cumsum(is_relevant, dtype=np.float32) / (1 + np.arange(is_relevant.shape[0]))\n",
    "    ap_score = np.sum(p_at_k) / np.min([relevant_items.shape[0], is_relevant.shape[0]])\n",
    "\n",
    "    return ap_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NETFLIX REAL 50.000.000 usuaris and 100.000 items\n",
    "%autosave 150\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "# Load Data set\n",
    "u_cols = ['user_id', 'sex', 'age', 'occupation', 'zip_code']\n",
    "users = pd.read_csv('./data/ml-1m/users.dat', sep='::', names=u_cols)\n",
    "\n",
    "r_cols = ['user_id', 'movie_id', 'rating', 'unix_timestamp']\n",
    "ratings = pd.read_csv('./data/ml-1m/ratings.dat', sep='::', names=r_cols)\n",
    "\n",
    "# the movies file contains columns indicating the movie's genres\n",
    "# let's only load the first three columns of the file with usecols\n",
    "m_cols = ['movie_id', 'title', 'release_date',]\n",
    "movies = pd.read_csv('./data/ml-1m/movies.dat', sep='::', names=m_cols, usecols=range(3), encoding='latin-1')\n",
    "\n",
    "# Construcci√≥ del DataFrame\n",
    "data = pd.merge(pd.merge(ratings, users), movies)\n",
    "data = data[['user_id','title', 'movie_id','rating','release_date','sex','age']]\n",
    "\n",
    "\n",
    "n_users = data.user_id.nunique()\n",
    "n_items = data.movie_id.nunique()\n",
    "print(\"La BD has \"+ str(data.shape[0]) +\" ratings\")\n",
    "print(\"La BD has \", n_users,\" users\")\n",
    "print(\"La BD has \", n_items, \" movies\")\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm # conda install -y tqdm\n",
    "\n",
    "class CollaborativeFiltering():\n",
    "    \"\"\" Collaborative filtering using a custom sim(u,u'). \"\"\"\n",
    "    \n",
    "    def __init__(self, similarity=SimPearson):\n",
    "        \"\"\" Constructor \"\"\"\n",
    "        self.sim_method=similarity# Gets recommendations for a person by using a weighted average\n",
    "        self.sim = {}\n",
    "        \n",
    "    def fit(self,train):\n",
    "        \"\"\" Prepare data structures for estimation. Similarity matrix for users \"\"\"\n",
    "        print(\"Learning...\")\n",
    "        self.train = train\n",
    "        allUsers=set(self.train['user_id'])\n",
    "        \n",
    "        for person1 in tqdm(allUsers):\n",
    "            self.sim.setdefault(person1, {})\n",
    "            a=self.train[self.train['user_id']==person1][['movie_id']]\n",
    "            data_reduced=pd.merge(self.train,a,on='movie_id') # reduce time complexity\n",
    "            for person2 in allUsers:\n",
    "                if person1==person2: continue\n",
    "                self.sim.setdefault(person2, {})\n",
    "                if(person1 in self.sim[person2]):continue # since is a simetric matrix\n",
    "                sim=self.sim_method(data_reduced,person1,person2)\n",
    "                if(sim<0):\n",
    "                    self.sim[person1][person2]=0\n",
    "                    self.sim[person2][person1]=0\n",
    "                else:\n",
    "                    self.sim[person1][person2]=sim\n",
    "                    self.sim[person2][person1]=sim\n",
    "                \n",
    "    def predict_score(self, user_id, movie_id):\n",
    "        totals={}\n",
    "        movie_users=self.train[self.train['movie_id'] ==movie_id]\n",
    "        rating_num=0.0\n",
    "        rating_den=0.0\n",
    "        allUsers=set(movie_users['user_id'])\n",
    "        for other in allUsers:\n",
    "            if user_id==other: continue \n",
    "            rating_num += self.sim[user_id][other] * float(movie_users[movie_users['user_id']==other]['rating'])\n",
    "            rating_den += self.sim[user_id][other]\n",
    "        if rating_den==0: \n",
    "            if self.train.rating[self.train['movie_id']==movie_id].mean()>0:\n",
    "                # return the mean movie rating if there is no similar for the computation\n",
    "                return self.train.rating[self.train['movie_id']==movie_id].mean()\n",
    "            else:\n",
    "                # else return mean user rating \n",
    "                return self.train.rating[self.train['user_id']==user_id].mean()\n",
    "        return rating_num/rating_den\n",
    "    \n",
    "    def predict_top(self, user_id, at=5, remove_seen=True):\n",
    "        '''Given a user_id predict its top AT items'''\n",
    "        seen_items = self.train[self.train.user_id==user_id].movie_id.values\n",
    "        unseen_items = set(self.train.movie_id.values) - set(seen_items)\n",
    "\n",
    "        predictions = [(item_id,self.predict_score(user_id,item_id)) for item_id in unseen_items]\n",
    "\n",
    "        sorted_predictions = sorted(predictions, key=lambda x: x[1],reverse = True)[:at]\n",
    "        return [i[0] for i in sorted_predictions]\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
